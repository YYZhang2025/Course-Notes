<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yuyang Zhang">

<title>Stanford CS336: Language Modeling from Scratch ‚Äì Learning Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../posts/Gen-AI/ucb-deep-unsupervised.html" rel="next">
<link href="../../posts/Gen-AI/kaist-diffusion-models.html" rel="prev">
<link href="../.././images/icon.avif" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-0348920b7671f696dc9078d39bff215e.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-cc542ae9cbb2dc3da5b9f84cb8966572.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-0fd53820e9cb11da4fdcad6c7683cbd0.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-cc542ae9cbb2dc3da5b9f84cb8966572.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="https://fonts.cdnfonts.com/css/cmu-sans-serif" rel="stylesheet">
<style>
div.callout-QA.callout {
  border-left-color: #e7f3ff;
}
div.callout-QA.callout-style-default > .callout-header {
  background-color: rgba(231, 243, 255, 0.13);
}
div.callout-QA .callout-toggle::before {  background-image: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="rgb(33, 37, 41)" class="bi bi-chevron-down" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1.646 4.646a.5.5 0 0 1 .708 0L8 10.293l5.646-5.647a.5.5 0 0 1 .708.708l-6 6a.5.5 0 0 1-.708 0l-6-6a.5.5 0 0 1 0-.708z"/></svg>');}
div.callout-QA.callout-style-default .callout-icon::before, div.callout-QA.callout-titled .callout-icon::before {
  content: 'üó®Ô∏è';
  background-image: none;
}
div.callout-summary.callout {
  border-left-color: #4b8bbe;
}
div.callout-summary.callout-style-default > .callout-header {
  background-color: rgba(75, 139, 190, 0.13);
}
div.callout-summary .callout-toggle::before {  background-image: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="rgb(33, 37, 41)" class="bi bi-chevron-down" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1.646 4.646a.5.5 0 0 1 .708 0L8 10.293l5.646-5.647a.5.5 0 0 1 .708.708l-6 6a.5.5 0 0 1-.708 0l-6-6a.5.5 0 0 1 0-.708z"/></svg>');}
div.callout-summary.callout-style-default .callout-icon::before, div.callout-summary.callout-titled .callout-icon::before {
  content: 'üìñ';
  background-image: none;
}
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../style/style.css">
<meta property="og:title" content="Stanford CS336: Language Modeling from Scratch ‚Äì Learning Notes">
<meta property="og:description" content="">
<meta property="og:image" content="./cs336.assets/lec01-tokenization.png">
<meta property="og:site_name" content="Learning Notes">
</head>

<body class="nav-sidebar docked quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../posts/Gen-AI/kaist-diffusion-models.html">Generative AI</a></li><li class="breadcrumb-item"><a href="../../posts/Gen-AI/stanford-cs336.html">Stanford CS336: <tag style="font-weight: bold">Language Modeling from Scratch</tag></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../index.html" class="sidebar-logo-link">
      <img src="../.././images/logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main tools-wide">
    <a href="https://yyzhang2000.github.io/Blog/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-globe"></i></a>
    <a href="https://github.com/YYZhang2025" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
    <a href="https://www.linkedin.com/in/zhang-yuyang/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-linkedin"></i></a>
    <a href="mailto:zhangyuyang1211@gmail.com" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-envelope"></i></a>
    <a href="https://noblecatt-1304922865.cos.ap-singapore.myqcloud.com/Yuyang_CV_General.pdf" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-file-person"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Reinforcement Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/RL/ucb-cs285.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">UCB CS285: <tag style="font-weight: bold">Deep Reinforcement Learning</tag></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Generative AI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Gen-AI/kaist-diffusion-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KAIST CS492(D): <em>Diffusion Models and Their Applications</em></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Gen-AI/stanford-cs336.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Stanford CS336: <tag style="font-weight: bold">Language Modeling from Scratch</tag></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Gen-AI/ucb-deep-unsupervised.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CS294-158: <em>Deep Unsupervised Learning</em></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Others</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../posts/Others/stanford-cs25.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Stanford CS25: Transformers United</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="1">
    <h2 id="toc-title">Table of Contents</h2>
   
  <ul>
  <li><a href="#lectures" id="toc-lectures" class="nav-link active" data-scroll-target="#lectures">Lectures</a>
  <ul>
  <li><a href="#lecture-01-overview-tokenization" id="toc-lecture-01-overview-tokenization" class="nav-link" data-scroll-target="#lecture-01-overview-tokenization">Lecture 01: Overview &amp; Tokenization</a>
  <ul>
  <li><a href="#tokenization" id="toc-tokenization" class="nav-link" data-scroll-target="#tokenization">Tokenization</a>
  <ul>
  <li><a href="#character-based-tokenization" id="toc-character-based-tokenization" class="nav-link" data-scroll-target="#character-based-tokenization">Character-Based Tokenization</a></li>
  <li><a href="#byte-based-tokenization" id="toc-byte-based-tokenization" class="nav-link" data-scroll-target="#byte-based-tokenization">Byte-Based Tokenization</a></li>
  <li><a href="#word-based-tokenization" id="toc-word-based-tokenization" class="nav-link" data-scroll-target="#word-based-tokenization">Word-Based Tokenization</a></li>
  <li><a href="#byte-pair-encoding-bpe" id="toc-byte-pair-encoding-bpe" class="nav-link" data-scroll-target="#byte-pair-encoding-bpe">Byte Pair Encoding (BPE)</a></li>
  </ul></li>
  <li><a href="#summary-of-lecture-01" id="toc-summary-of-lecture-01" class="nav-link" data-scroll-target="#summary-of-lecture-01">Summary of Lecture 01</a></li>
  </ul></li>
  <li><a href="#lecture-02-pytorch-resource-accounting" id="toc-lecture-02-pytorch-resource-accounting" class="nav-link" data-scroll-target="#lecture-02-pytorch-resource-accounting">Lecture 02: Pytorch, Resource Accounting</a>
  <ul>
  <li><a href="#memory-accounting" id="toc-memory-accounting" class="nav-link" data-scroll-target="#memory-accounting">Memory Accounting</a></li>
  <li><a href="#compute-account" id="toc-compute-account" class="nav-link" data-scroll-target="#compute-account">Compute Account</a>
  <ul>
  <li><a href="#eniops" id="toc-eniops" class="nav-link" data-scroll-target="#eniops">Eniops</a></li>
  <li><a href="#count-flops-for-operations" id="toc-count-flops-for-operations" class="nav-link" data-scroll-target="#count-flops-for-operations">Count Flops for operations</a></li>
  </ul></li>
  <li><a href="#models" id="toc-models" class="nav-link" data-scroll-target="#models">Models</a>
  <ul>
  <li><a href="#model-parameters-initialization" id="toc-model-parameters-initialization" class="nav-link" data-scroll-target="#model-parameters-initialization">Model Parameters Initialization</a></li>
  <li><a href="#random-seed" id="toc-random-seed" class="nav-link" data-scroll-target="#random-seed">Random Seed</a></li>
  <li><a href="#data-loading" id="toc-data-loading" class="nav-link" data-scroll-target="#data-loading">Data Loading</a></li>
  <li><a href="#optimizer" id="toc-optimizer" class="nav-link" data-scroll-target="#optimizer">Optimizer</a></li>
  <li><a href="#training-loop" id="toc-training-loop" class="nav-link" data-scroll-target="#training-loop">Training Loop</a></li>
  <li><a href="#checkpointing" id="toc-checkpointing" class="nav-link" data-scroll-target="#checkpointing">Checkpointing</a></li>
  <li><a href="#mixed-precision-training" id="toc-mixed-precision-training" class="nav-link" data-scroll-target="#mixed-precision-training">Mixed Precision Training</a></li>
  </ul></li>
  <li><a href="#summary-of-lecture-02" id="toc-summary-of-lecture-02" class="nav-link" data-scroll-target="#summary-of-lecture-02">Summary of Lecture 02</a></li>
  </ul></li>
  <li><a href="#lecture-03-architectures-hyperparameters" id="toc-lecture-03-architectures-hyperparameters" class="nav-link" data-scroll-target="#lecture-03-architectures-hyperparameters">Lecture 03: Architectures &amp; Hyperparameters</a></li>
  <li><a href="#lecture-04-mixture-of-experts" id="toc-lecture-04-mixture-of-experts" class="nav-link" data-scroll-target="#lecture-04-mixture-of-experts">Lecture 04: Mixture of Experts</a></li>
  <li><a href="#lecture-05-06-gpu-kernels-triton" id="toc-lecture-05-06-gpu-kernels-triton" class="nav-link" data-scroll-target="#lecture-05-06-gpu-kernels-triton">Lecture 05 &amp; 06: GPU, Kernels, Triton</a></li>
  <li><a href="#lecture-07-08-parallelism" id="toc-lecture-07-08-parallelism" class="nav-link" data-scroll-target="#lecture-07-08-parallelism">Lecture 07 &amp; 08: Parallelism</a></li>
  <li><a href="#lecture-09-11-scaling-laws" id="toc-lecture-09-11-scaling-laws" class="nav-link" data-scroll-target="#lecture-09-11-scaling-laws">Lecture 09 &amp; 11: Scaling Laws</a></li>
  <li><a href="#lecture-10-inference" id="toc-lecture-10-inference" class="nav-link" data-scroll-target="#lecture-10-inference">Lecture 10: Inference</a></li>
  <li><a href="#lecture-12-evaluation" id="toc-lecture-12-evaluation" class="nav-link" data-scroll-target="#lecture-12-evaluation">Lecture 12: Evaluation</a></li>
  <li><a href="#lecture-13-14-data" id="toc-lecture-13-14-data" class="nav-link" data-scroll-target="#lecture-13-14-data">Lecture 13 &amp; 14: Data</a></li>
  <li><a href="#lecture-15-16-17-alignment-sft-rlhf" id="toc-lecture-15-16-17-alignment-sft-rlhf" class="nav-link" data-scroll-target="#lecture-15-16-17-alignment-sft-rlhf">Lecture 15, 16 &amp; 17: Alignment: SFT/ RLHF</a></li>
  </ul></li>
  <li><a href="#assignments" id="toc-assignments" class="nav-link" data-scroll-target="#assignments">Assignments</a>
  <ul>
  <li><a href="#assignment-01-basics" id="toc-assignment-01-basics" class="nav-link" data-scroll-target="#assignment-01-basics">Assignment 01: Basics</a>
  <ul>
  <li><a href="#preparation" id="toc-preparation" class="nav-link" data-scroll-target="#preparation">Preparation</a>
  <ul>
  <li><a href="#clone-assignment-repository" id="toc-clone-assignment-repository" class="nav-link" data-scroll-target="#clone-assignment-repository">Clone Assignment Repository</a></li>
  <li><a href="#download-dataset" id="toc-download-dataset" class="nav-link" data-scroll-target="#download-dataset">Download Dataset</a></li>
  <li><a href="#install-dependencies" id="toc-install-dependencies" class="nav-link" data-scroll-target="#install-dependencies">Install Dependencies</a></li>
  </ul></li>
  <li><a href="#byte-pair-encoding-bpe-tokenizer" id="toc-byte-pair-encoding-bpe-tokenizer" class="nav-link" data-scroll-target="#byte-pair-encoding-bpe-tokenizer">Byte-Pair Encoding (BPE) Tokenizer</a>
  <ul>
  <li><a href="#the-unicode-standard" id="toc-the-unicode-standard" class="nav-link" data-scroll-target="#the-unicode-standard">The Unicode Standard</a></li>
  <li><a href="#unicode-encoding" id="toc-unicode-encoding" class="nav-link" data-scroll-target="#unicode-encoding">Unicode Encoding</a></li>
  <li><a href="#bpe-tokenizer-training" id="toc-bpe-tokenizer-training" class="nav-link" data-scroll-target="#bpe-tokenizer-training">BPE Tokenizer Training</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#assignment-02-system" id="toc-assignment-02-system" class="nav-link" data-scroll-target="#assignment-02-system">Assignment 02: System</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../posts/Gen-AI/kaist-diffusion-models.html">Generative AI</a></li><li class="breadcrumb-item"><a href="../../posts/Gen-AI/stanford-cs336.html">Stanford CS336: <tag style="font-weight: bold">Language Modeling from Scratch</tag></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Stanford CS336: <tag style="font-weight: bold">Language Modeling from Scratch</tag></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Yuyang Zhang </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<hr>
<p>Lecture Website: <a href="https://stanford-cs336.github.io/spring2025/">Link</a></p>
<p>Lecture Video: <a href="https://www.youtube.com/playlist?list=PLoROMvodv4rOY23Y0BoGoBGgQ1zmU_MT_">YouTube</a></p>
<hr>
<p>This is a collection of notes and code for the <a href="https://stanford-cs336.github.io/spring2025/">Stanford CS336: Language Modeling from Scratch</a> course. This is course is designed to teach students how to build a ‚Äúlarge‚Äù language model (LLM) from scratch, covering from bottom to top, including the:</p>
<ul>
<li>data collection and preprocessing,</li>
<li>tokenization,</li>
<li>model architecture and variations,</li>
<li>pre-training,</li>
<li>post-training,</li>
<li>inference</li>
<li>model evaluation.</li>
</ul>
<p>The course is designed to provide a comprehensive understanding of how LLMs work and how to build them from scratch.</p>
<p>There are total <tag style="color:orange">17 Lectures</tag> and <tag style="color:orange">5 Assignments</tag> in this course.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>It might takes <tag style="color:red">200+</tag> hours to finish the course, including the lectures and assignments. But hang in there, it will be worth it!!!</p>
</div>
</div>
<section id="lectures" class="level1 page-columns page-full">
<h1>Lectures</h1>
<section id="lecture-01-overview-tokenization" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="lecture-01-overview-tokenization">Lecture 01: Overview &amp; Tokenization</h2>
<div class="callout callout-style-default callout-summary callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Summary of Lecture 01
</div>
</div>
<div class="callout-body-container callout-body">
<p>Byte Pair Encoding (BPE) is a simple yet effective <strong>tokenization algorithm</strong> that adaptively merges frequent character pairs to create a compact vocabulary, balancing compression efficiency and reversibility for language modeling.</p>
</div>
</div>
<section id="tokenization" class="level3">
<h3 class="anchored" data-anchor-id="tokenization">Tokenization</h3>
<p>Tokenization is <u>the process of converting <em>raw text</em> into a <em>sequence of tokens</em>(usually is represented by <em>integer indices</em>)</u>, which are the basic units of meaning in a language model.</p>
<p>There are different level of tokenization, such as:</p>
<ul>
<li><strong>Character-level</strong>: Each character is treated as a separate token.</li>
<li><strong>Word-level</strong>: Each word is treated as a separate token.</li>
<li><strong>Subword-level</strong>: Words are split into smaller units, such as prefixes, suffixes, or common subwords, to handle rare or out-of-vocabulary words more effectively.</li>
<li><strong>Byte-level</strong>: Each byte of the text is treated as a separate token, which can handle any character in the Unicode standard.</li>
</ul>
<div id="fig-tokenization-example" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tokenization-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./cs336.assets/lec01-tokenization.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tokenization-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: An example of tokenization, the interactive demo of the tokenization process can be found <a href="https://tiktokenizer.vercel.app/">here</a>
</figcaption>
</figure>
</div>
<p>Before diving into the details of each tokenization algorithms , let‚Äôs first define a framework for tokenization in Python code: A <code>Tokenizer</code> is a class that implements the encode and decode methods for tokenization:</p>
<ul>
<li><code>encode(string)</code> method <u>takes a string of text and converts it into a sequence of integer indices</u>, which are the <strong>tokens</strong>.</li>
<li><code>decode(indices)</code> method <u>takes a sequence of integer indices and converts it back into a string of text</u>.</li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">class</span> Tokenizer:</span>
<span id="cb1-2"><a href="#cb1-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, config):</span>
<span id="cb1-3"><a href="#cb1-3"></a></span>
<span id="cb1-4"><a href="#cb1-4"></a>    <span class="kw">def</span> encode(<span class="va">self</span>, string: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">list</span>[<span class="bu">int</span>]:</span>
<span id="cb1-5"><a href="#cb1-5"></a>        <span class="cf">pass</span></span>
<span id="cb1-6"><a href="#cb1-6"></a></span>
<span id="cb1-7"><a href="#cb1-7"></a>    <span class="kw">def</span> decode(<span class="va">self</span>, indices: <span class="bu">list</span>[<span class="bu">int</span>]) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb1-8"><a href="#cb1-8"></a>        <span class="cf">pass</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <code>Tokenizer</code> will generate a list of tokens from the input text, the number of the tokens is called the <strong>vocabulary size</strong>.</p>
<p>One of the good quantity to measure the tokenization algorithm is the <strong>compression ratio</strong>, which is defined as the <em>ratio of the number of bytes of the input text to the number of tokens</em>. <u>A higher compression ratio indicates that the tokenization algorithm is more efficient in representing the input text</u>. The compression ratio can be calculated as:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="kw">def</span> get_compression_ratio(string: <span class="bu">str</span>, indices: <span class="bu">list</span>[<span class="bu">int</span>]) <span class="op">-&gt;</span> <span class="bu">float</span>:</span>
<span id="cb2-2"><a href="#cb2-2"></a>    <span class="co"># Calculate the compression ratio of the tokenization algorithm</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>    <span class="cf">return</span> <span class="bu">len</span>(<span class="bu">bytes</span>(string, <span class="st">'utf-8'</span>)) <span class="op">/</span> <span class="bu">len</span>(indices)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Now, let‚Äôs discuss those four tokenization algorithms in detail:</p>
<section id="character-based-tokenization" class="level4">
<h4 class="anchored" data-anchor-id="character-based-tokenization">Character-Based Tokenization</h4>
<p>A Unicode string is a sequence of Unicode code points, which can be represented as a sequence of integers. Each character in the string is treated as a separate token, for example:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="bu">ord</span>(<span class="st">'a'</span>)   <span class="co"># 97 </span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="bu">chr</span>(<span class="dv">97</span>)   <span class="co"># 'a'</span></span>
<span id="cb3-3"><a href="#cb3-3"></a></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="bu">ord</span>(<span class="st">'üåç'</span>) <span class="co"># 127757</span></span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="bu">chr</span>(<span class="dv">127757</span>) <span class="co"># 'üåç'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can implement a simple character-based tokenizer as follows:</p>
<div id="2a971e5d" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">class</span> CharacterTokenizer(Tokenizer):</span>
<span id="cb4-2"><a href="#cb4-2"></a>    <span class="kw">def</span> encode(<span class="va">self</span>, string: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">list</span>[<span class="bu">int</span>]:</span>
<span id="cb4-3"><a href="#cb4-3"></a>        <span class="cf">return</span> [<span class="bu">ord</span>(c) <span class="cf">for</span> c <span class="kw">in</span> string]</span>
<span id="cb4-4"><a href="#cb4-4"></a>    <span class="kw">def</span> decode(<span class="va">self</span>, indices: <span class="bu">list</span>[<span class="bu">int</span>]) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb4-5"><a href="#cb4-5"></a>        <span class="cf">return</span> <span class="st">''</span>.join(<span class="bu">chr</span>(i) <span class="cf">for</span> i <span class="kw">in</span> indices)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>One of the main drawbacks of character-based tokenization is that it can lead to a large vocabulary size (there are approximately <a href="https://en.wikipedia.org/wiki/List_of_Unicode_characters">150K unicode characters</a>), which can make the model more difficult to train and less efficient in terms of memory usage. And some character are not commonly used in the text(e.g.&nbsp;‚Äòüåç‚Äô), which is inefficient use of the vocabulary.</p>
</section>
<section id="byte-based-tokenization" class="level4">
<h4 class="anchored" data-anchor-id="byte-based-tokenization">Byte-Based Tokenization</h4>
<p>Unicode strings can be encoded as a sequence of bytes using UTF-8 encoding. Each byte can be represented by integers in the range of 0 to 255. Some Unicode characters are represented by one byte, others take multiple bytes:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="bu">bytes</span>(<span class="st">'a'</span>, <span class="st">'utf-8'</span>)  <span class="co"># b'a'</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="bu">bytes</span>(<span class="st">'üåç'</span>, <span class="st">'utf-8'</span>)  <span class="co"># b'\xf0\x9f\x8c\x8d'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can implement a simple byte-based tokenizer as follows:</p>
<div id="0518df0e" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw">class</span> ByteTokenizer(Tokenizer):</span>
<span id="cb6-2"><a href="#cb6-2"></a>    <span class="kw">def</span> encode(<span class="va">self</span>, string: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">list</span>[<span class="bu">int</span>]:</span>
<span id="cb6-3"><a href="#cb6-3"></a>        <span class="cf">return</span> <span class="bu">list</span>(<span class="bu">bytes</span>(string, <span class="st">'utf-8'</span>))</span>
<span id="cb6-4"><a href="#cb6-4"></a>    <span class="kw">def</span> decode(<span class="va">self</span>, indices: <span class="bu">list</span>[<span class="bu">int</span>]) <span class="op">-&gt;</span> <span class="bu">str</span>:</span>
<span id="cb6-5"><a href="#cb6-5"></a>        <span class="cf">return</span> <span class="bu">bytes</span>(indices).decode(<span class="st">'utf-8'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As we can expected, the compression ratio is 1, which is terrible.</p>
<p>The <strong>vocabulary size</strong> is 256, which is a nice property because it is fixed and covers all possible bytes, which means we will not get out-of-vocabulary (OOV) tokens. However, the main drawback is that it can lead to long sequences, since each character (even multi-byte Unicode characters) is split into multiple tokens. This can make training less efficient and increase the computational cost for language models, given that the context length of a Transformer model is limited.</p>
</section>
<section id="word-based-tokenization" class="level4">
<h4 class="anchored" data-anchor-id="word-based-tokenization">Word-Based Tokenization</h4>
<p>Another common approach is to tokenize the text into words, where each word is treated as a separate token. We can use <a href="https://en.wikipedia.org/wiki/Regular_expression">regular expression</a> to <u>split the text into words</u>.</p>
<p>for example the GPT-2 regular expression is :</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a>GPT2_TOKENIZER_REGEX <span class="op">=</span> <span class="vs">r"""'</span>(?:<span class="pp">[sdmt]</span><span class="cf">|</span><span class="vs">ll</span><span class="cf">|</span><span class="vs">ve</span><span class="cf">|</span><span class="vs">re</span>)<span class="cf">|</span><span class="vs"> </span><span class="op">?</span><span class="ch">\p{L}</span><span class="op">+</span><span class="cf">|</span><span class="vs"> </span><span class="op">?</span><span class="ch">\p{N}</span><span class="op">+</span><span class="cf">|</span><span class="vs"> </span><span class="op">?</span><span class="pp">[^</span><span class="dv">\s</span><span class="ch">\p{L}\p{N}</span><span class="pp">]</span><span class="op">+</span><span class="cf">|</span><span class="dv">\s</span><span class="op">+</span><span class="ex">(</span><span class="fu">?!</span><span class="dv">\S</span><span class="ex">)</span><span class="cf">|</span><span class="dv">\s</span><span class="op">+</span><span class="vs">"""</span></span>
<span id="cb7-2"><a href="#cb7-2"></a>segments <span class="op">=</span> re.findall(GPT2_TOKENIZER_REGEX, string)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>After we get the segments, we can assign each segment to a unique integer index, which is the token. However there are several problem with this word-level tokenization:</p>
<ul>
<li>The number of words is huge.</li>
<li>Many words are rare and the model won‚Äôt learn much about them.</li>
<li>The vocabulary size is not fixed, which can lead to out-of-vocabulary (OOV) tokens. New words we haven‚Äôt seen during training will be treated as <code>UNK</code> tokens, which can lead to a loss of information and context.</li>
</ul>
</section>
<section id="byte-pair-encoding-bpe" class="level4">
<h4 class="anchored" data-anchor-id="byte-pair-encoding-bpe">Byte Pair Encoding (BPE)</h4>
<p>The basic idea of BPE is to <u>iteratively merge the most frequent pairs of characters or subwords in the text until a desired vocabulary size is reached</u>. This allows for a more efficient representation of the text, as it can capture common subwords and reduce the overall vocabulary size. The intuition behind BPE is that common sequences of characters are represented by a single token, rare sequences are represented by many tokens.</p>
<blockquote class="blockquote">
<p>The GPT-2 paper used word-based tokenization to break up the text into initial segments and run the original BPE algorithm on each segment.</p>
</blockquote>
<p>Here are the steps to implement BPE:</p>
<ol type="1">
<li><strong>Initialize</strong>: Start with a vocabulary that contains all unique characters in the text, usually start with 0-255</li>
<li><strong>Count Pairs</strong>: Count all adjacent character pairs in the text.</li>
<li><strong>Merge</strong>: Find the most frequent pair and merge it into a new token.</li>
<li><strong>Update</strong>: Replace all occurrences of the merged pair in the text with the new token.</li>
<li><strong>Repeat</strong>: Repeat steps 2-4 until the desired vocabulary size is reached.</li>
</ol>
<div id="df2586bf" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="at">@dataclass</span>(frozen<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="kw">class</span> BPETokenizerParams:</span>
<span id="cb8-3"><a href="#cb8-3"></a>    vocab: <span class="bu">dict</span>[<span class="bu">int</span>, <span class="bu">bytes</span>]   <span class="co"># Mapping of token indices to byte sequences</span></span>
<span id="cb8-4"><a href="#cb8-4"></a>    merges: <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>], <span class="bu">int</span>]  <span class="co"># Mapping of pairs to their frequency</span></span>
<span id="cb8-5"><a href="#cb8-5"></a></span>
<span id="cb8-6"><a href="#cb8-6"></a><span class="kw">def</span> merge(indices: <span class="bu">list</span>[<span class="bu">int</span>], pair: <span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>], new_index:<span class="bu">int</span>)  <span class="op">-&gt;</span> <span class="bu">list</span>[<span class="bu">int</span>]:</span>
<span id="cb8-7"><a href="#cb8-7"></a>    new_indices <span class="op">=</span> []</span>
<span id="cb8-8"><a href="#cb8-8"></a>    i <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb8-9"><a href="#cb8-9"></a>    <span class="cf">while</span> i<span class="op">&lt;</span> <span class="bu">len</span>(indices):</span>
<span id="cb8-10"><a href="#cb8-10"></a>        <span class="cf">if</span> i <span class="op">+</span> <span class="dv">1</span> <span class="op">&lt;</span> <span class="bu">len</span>(indices) <span class="kw">and</span> indices[i] <span class="op">==</span> pair[<span class="dv">0</span>] <span class="kw">and</span> indices[i <span class="op">+</span> <span class="dv">1</span>] <span class="op">==</span> pair[<span class="dv">1</span>]:</span>
<span id="cb8-11"><a href="#cb8-11"></a>            new_indices.append(new_index)  <span class="co"># Replace the pair with the new index</span></span>
<span id="cb8-12"><a href="#cb8-12"></a>            i <span class="op">+=</span> <span class="dv">2</span>  <span class="co"># Skip the next index since it's part of the pair</span></span>
<span id="cb8-13"><a href="#cb8-13"></a>        <span class="cf">else</span>:</span>
<span id="cb8-14"><a href="#cb8-14"></a>            new_indices.append(indices[i])  <span class="co"># Keep the current index</span></span>
<span id="cb8-15"><a href="#cb8-15"></a>            i <span class="op">+=</span> <span class="dv">1</span>  <span class="co"># Move to the next index</span></span>
<span id="cb8-16"><a href="#cb8-16"></a>    <span class="cf">return</span> new_indices</span>
<span id="cb8-17"><a href="#cb8-17"></a></span>
<span id="cb8-18"><a href="#cb8-18"></a><span class="kw">class</span> BPETokenizer(Tokenizer):</span>
<span id="cb8-19"><a href="#cb8-19"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, params: BPETokenizerParams):</span>
<span id="cb8-20"><a href="#cb8-20"></a>        <span class="va">self</span>.params <span class="op">=</span> params </span>
<span id="cb8-21"><a href="#cb8-21"></a>    </span>
<span id="cb8-22"><a href="#cb8-22"></a>    <span class="kw">def</span> encode(<span class="va">self</span>, string: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="bu">list</span>[<span class="bu">int</span>]:</span>
<span id="cb8-23"><a href="#cb8-23"></a>        indices <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="bu">int</span>, string.encode(<span class="st">'utf-8'</span>))) <span class="co"># Convert string to byte indices</span></span>
<span id="cb8-24"><a href="#cb8-24"></a>        <span class="cf">for</span> pair, new_index <span class="kw">in</span> <span class="va">self</span>.params.merges.items():</span>
<span id="cb8-25"><a href="#cb8-25"></a>            indices <span class="op">=</span> merge(indices, pair, new_index)  </span>
<span id="cb8-26"><a href="#cb8-26"></a>        <span class="cf">return</span> indices</span>
<span id="cb8-27"><a href="#cb8-27"></a>    </span>
<span id="cb8-28"><a href="#cb8-28"></a>    <span class="kw">def</span> decode(<span class="va">self</span>, indices: <span class="bu">list</span>[<span class="bu">int</span>]) <span class="op">-&gt;</span> <span class="bu">str</span>: </span>
<span id="cb8-29"><a href="#cb8-29"></a>        byte_list <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="va">self</span>.params.vocab.get, indices))  <span class="co"># Convert indices to bytes</span></span>
<span id="cb8-30"><a href="#cb8-30"></a>        string <span class="op">=</span> <span class="st">b''</span>.join(byte_list)  <span class="co"># Join bytes into a single byte string</span></span>
<span id="cb8-31"><a href="#cb8-31"></a>        <span class="cf">return</span> string.decode(<span class="st">'utf-8'</span>)  <span class="co"># Decode byte string to UTF-8</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To train an BPE tokenizer, we need to count the frequency of pairs in the text and merge them iteratively. The <code>BPETokenizerParams</code> class holds the vocabulary and merge rules, which can be generated from a training corpus.</p>
<div id="60b2c1e6" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="kw">def</span> train_bpe_tokenizer(string: <span class="bu">str</span>, num_merges: <span class="bu">int</span>) <span class="op">-&gt;</span> BPETokenizerParams:</span>
<span id="cb9-2"><a href="#cb9-2"></a>    <span class="co"># Initialize vocabulary with single characters</span></span>
<span id="cb9-3"><a href="#cb9-3"></a>    vocab: <span class="bu">dict</span>[<span class="bu">int</span>, <span class="bu">bytes</span>] <span class="op">=</span> {x: <span class="bu">bytes</span>([x]) <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">256</span>)}  <span class="co"># index -&gt; bytes, 256 unique bytes for UTF-8</span></span>
<span id="cb9-4"><a href="#cb9-4"></a>    merges: <span class="bu">dict</span>[<span class="bu">tuple</span>[<span class="bu">int</span>, <span class="bu">int</span>], <span class="bu">int</span>] <span class="op">=</span> {}  <span class="co"># index1, index2 =&gt; merged index</span></span>
<span id="cb9-5"><a href="#cb9-5"></a>    </span>
<span id="cb9-6"><a href="#cb9-6"></a>    <span class="co"># Convert string to byte indices</span></span>
<span id="cb9-7"><a href="#cb9-7"></a>    indices <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="bu">int</span>, string.encode(<span class="st">'utf-8'</span>)))</span>
<span id="cb9-8"><a href="#cb9-8"></a>    </span>
<span id="cb9-9"><a href="#cb9-9"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_merges):</span>
<span id="cb9-10"><a href="#cb9-10"></a>        <span class="co"># Count pairs</span></span>
<span id="cb9-11"><a href="#cb9-11"></a>        counts <span class="op">=</span> defaultdict(<span class="bu">int</span>)</span>
<span id="cb9-12"><a href="#cb9-12"></a>        <span class="cf">for</span> index1, index2 <span class="kw">in</span> <span class="bu">zip</span>(indices[:<span class="op">-</span><span class="dv">1</span>], indices[<span class="dv">1</span>:]):</span>
<span id="cb9-13"><a href="#cb9-13"></a>            counts[(index1, index2)] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb9-14"><a href="#cb9-14"></a></span>
<span id="cb9-15"><a href="#cb9-15"></a>        <span class="co"># Find the most frequent pair</span></span>
<span id="cb9-16"><a href="#cb9-16"></a></span>
<span id="cb9-17"><a href="#cb9-17"></a>        most_frequent_pair <span class="op">=</span> <span class="bu">max</span>(counts, key<span class="op">=</span>counts.get)</span>
<span id="cb9-18"><a href="#cb9-18"></a>        </span>
<span id="cb9-19"><a href="#cb9-19"></a>        <span class="co"># Create a new token for the merged pair</span></span>
<span id="cb9-20"><a href="#cb9-20"></a>        new_index <span class="op">=</span> <span class="dv">256</span> <span class="op">+</span> i </span>
<span id="cb9-21"><a href="#cb9-21"></a>        merges[most_frequent_pair] <span class="op">=</span> new_index</span>
<span id="cb9-22"><a href="#cb9-22"></a>        vocab[new_index] <span class="op">=</span> vocab[index1] <span class="op">+</span> vocab[index2]  <span class="co"># Merge the byte sequences</span></span>
<span id="cb9-23"><a href="#cb9-23"></a>        </span>
<span id="cb9-24"><a href="#cb9-24"></a>        <span class="co"># Merge the pair in the indices</span></span>
<span id="cb9-25"><a href="#cb9-25"></a>        indices <span class="op">=</span> merge(indices, most_frequent_pair, new_index)</span>
<span id="cb9-26"><a href="#cb9-26"></a>    </span>
<span id="cb9-27"><a href="#cb9-27"></a>    <span class="cf">return</span> BPETokenizerParams(vocab<span class="op">=</span>vocab, merges<span class="op">=</span>merges)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can save the <code>BPETokenizerParams</code> to a file and load it later to use the tokenizer. The BPE algorithm is efficient in terms of compression ratio, as it can adaptively merge frequent subwords to form a compact vocabulary, while still being reversible.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This implementation of BPE is a simplified version, and there are many optimizations and variations that can be applied to improve the efficiency and performance of the algorithm. For example, we can use a <a href="https://en.wikipedia.org/wiki/Priority_queue">priority queue</a> to efficiently find the most frequent pair. And we can also use more advanced techniques to speed up the merging process, such as caching and batching.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Further Reading">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Further Reading
</div>
</div>
<div class="callout-body-container callout-body">
<p>For those are more interested in the BPE, I highly recommend this video by <a href="https://www.youtube.com/@AndrejKarpathy">Andrej Karpathy</a>, which provides a detailed explanation of the BPE algorithm.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/zduSFxRajkE?si=hQlXUYOgclHVA4je" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</section>
</section>
<section id="summary-of-lecture-01" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="summary-of-lecture-01">Summary of Lecture 01</h3>
<p>In this lecture, we learned about the concept of the tokenization, which is the process of converting raw text into a sequence of tokens. We discussed four different tokenization algorithms: character-based, byte-based, word-based, and byte pair encoding (BPE). Each algorithm has its own advantages and disadvantages. We also learned how to measure the efficiency of a tokenization algorithm using the compression ratio. We will implemented more fancy version of the BPE algorithm in the assignment 01, which will be used to build a transformer model from scratch.</p>
<p>Below are the summary of four different tokenization algorithms:</p>
<div class="column-page">
<div id="tbl-tokenization-summary" class="hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<div aria-describedby="tbl-tokenization-summary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-hover table">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Tokenization Type</th>
<th>Description</th>
<th>Compression Ratio</th>
<th>Vocabulary Size</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Character-Based</td>
<td>Each character is a token (Unicode code point).</td>
<td>Low</td>
<td>Large (all characters)</td>
<td>Simple; handles any language</td>
<td>Inefficient; large vocab; rare chars waste tokens</td>
</tr>
<tr class="even">
<td>Byte-Based</td>
<td>Each byte from UTF-8 encoding is a token (0‚Äì255).</td>
<td>~1</td>
<td>Fixed (256)</td>
<td>Fixed vocab; language-agnostic</td>
<td>Long sequences for Unicode; inefficient for modeling semantics</td>
</tr>
<tr class="odd">
<td>Word-Based</td>
<td>Words (or regex-matched units) are tokens.</td>
<td>Medium</td>
<td>Large and dynamic</td>
<td>Intuitive; better compression than char/byte</td>
<td>Poor generalization; large vocab; OOV issues with <code>UNK</code></td>
</tr>
<tr class="even">
<td>Byte Pair Encoding (BPE)</td>
<td>Iteratively merges frequent subword pairs to form subword tokens.</td>
<td>High</td>
<td>Medium (tunable)</td>
<td>Efficient; balances granularity and vocab size</td>
<td>Merge rules are corpus-dependent; needs initial segmentation</td>
</tr>
</tbody>
</table>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-tbl" id="tbl-tokenization-summary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Summary of 4 different tokenization algorithms
</figcaption>
</figure>
</div>
</div>
</section>
</section>
<section id="lecture-02-pytorch-resource-accounting" class="level2">
<h2 class="anchored" data-anchor-id="lecture-02-pytorch-resource-accounting">Lecture 02: Pytorch, Resource Accounting</h2>
<p>h100_bytes = 80e9</p>
<p>Bytes_per_parameter = 4 + 4 + ( 4+ 4) =&gt; Parameters, gradient, optimizer state</p>
<p>Num Paramter = (h100_byes * 8) / Bytes_per_parameter 4e10</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a>x <span class="op">=</span> torch.tensor([</span>
<span id="cb10-2"><a href="#cb10-2"></a>    [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>],</span>
<span id="cb10-3"><a href="#cb10-3"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="memory-accounting" class="level3">
<h3 class="anchored" data-anchor-id="memory-accounting">Memory Accounting</h3>
<p>Let‚Äôs introduce three most common data types used in deep learning: <code>float32</code>, <code>float16</code>, and <code>bfloat16</code>.</p>
<p><code>float32</code> is the most common(default) data type used in deep learning, which uses 4 bytes per element.</p>
<div id="fig-fp32-representation" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fp32-representation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/fp32.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fp32-representation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: The representation of float32 in memory
</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Float Representation">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Float Representation
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <code>exponent</code> used to represent the dynamic range of the number, for <code>float32</code>, it uses 8 bits for the exponent, which allows for a dynamic range of approximately 1.18e-38 to 3.4e+38. The <code>fraction</code> is used to represent the precision of the number, which is also known as resolution. For <code>float32</code>, it uses 23 bits for the fraction, which allows for a precision of approximately 7 decimal digits. To represent a number in <code>float32</code>, it uses the following formula: <span class="math display">\[
\begin{aligned}
\text{value}
&amp;= (-1)^{b_{31}} \times 2^{(b_{30}b_{29} \dots b_{23})_2 - 127} \times (1.b_{22}b_{21} \dots b_{0})_2 \\
&amp;= (-1)^{\text{sign}} \times 2^{(E - 127)} \times \left( 1 + \sum_{i=1}^{23} b_{23 - i} \cdot 2^{-i} \right)
\end{aligned}
\]</span> where <code>sign</code> is the sign bit, <code>exponent</code> is the exponent value, and <code>fraction</code> is the fraction value. The exponent is biased by 127, which means that the exponent value is stored as the actual exponent plus 127. This allows for both positive and negative exponents to be represented.</p>
</div>
</div>
<p>Memory is determined by <u>the number of values in the tensor and the data type of the tensor</u>. The memory usage can be calculated as: <span id="eq-memory-account-tensor"><span class="math display">\[
\text{Memory} = \text{Number of Values} \times \text{Bytes per Value}
\tag{1}\]</span></span> which can be calculated as:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="kw">def</span> get_memory_usage(x: torch.Tensor):</span>
<span id="cb11-2"><a href="#cb11-2"></a>    <span class="cf">return</span> x.numel() <span class="op">*</span> x.element_size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <code>float32</code> takes 4 bytes per element, for the LLM, this is a lot of memory. We are use <code>float16</code> to reduce the memory usage by half, which is 2 bytes per element. This is a common practice in deep learning to save memory and speed up training.</p>
<div id="fig-fp16-representation" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fp16-representation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/fp16.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fp16-representation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: The representation of float16 in memory
</figcaption>
</figure>
</div>
<p>The <code>float16</code> cuts down the memory usage by half, but it has a smaller dynamic range and precision compared to <code>float32</code>. This can lead to numerical instability and loss of precision in some cases, especially when dealing with very large or very small numbers.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1e-8</span>], dtype<span class="op">=</span>torch.float16)  </span>
<span id="cb12-2"><a href="#cb12-2"></a><span class="cf">assert</span> x <span class="op">==</span> <span class="dv">0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>when the underflow or overflow happens, the value will be rounded to 0 or infinity, which might cause the instability in the training process.</p>
<p>Another data type is <code>bfloat16</code>, which is a 16-bit floating point format that has the same dynamic range as <code>float32</code>, but with less precision. It uses 8 bits for the exponent and 7 bits for the fraction, which allows for a dynamic range of approximately 3.4e-38 to 3.4e+38, but with a precision of only 2 decimal digits.</p>
<div id="fig-bf16-representation" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bf16-representation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/bf16.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bf16-representation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: The representation of bfloat16 in memory
</figcaption>
</figure>
</div>
<p>In conclusion, the choice of data type can have a significant impact on the memory usage and performance of the model. The <code>float32</code> is the most common data type used in deep learning, but it can be memory-intensive. The <code>float16</code> and <code>bfloat16</code> are commonly used to reduce the memory usage, but they can lead to numerical instability and loss of precision in some cases. One of the common practice to combine <code>float16</code> and <code>float32</code> is to <u>use <code>float16</code> for the model parameters and gradients, and <code>float32</code> for the optimizer state</u>. This is known as <strong>mixed precision training</strong><span class="citation" data-cites="MixedPrecisionTraining2018micikevicius">(<a href="#ref-MixedPrecisionTraining2018micikevicius" role="doc-biblioref">Micikevicius et al. 2018</a>)</span>, which can save memory and speed up training without sacrificing too much performance.</p>
</section>
<section id="compute-account" class="level3">
<h3 class="anchored" data-anchor-id="compute-account">Compute Account</h3>
<p>By defaults, all the tensors are stored in the CPU memory, which is not efficient for training deep learning models. We can move the tensors to the GPU memory by calling the <code>to</code> method on the tensor, which will move the tensor to the specified device.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a>x <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb13-2"><a href="#cb13-2"></a>x <span class="op">=</span> x.to(<span class="st">'cuda'</span>)  <span class="co"># Move tensor to GPU</span></span>
<span id="cb13-3"><a href="#cb13-3"></a></span>
<span id="cb13-4"><a href="#cb13-4"></a>num_gpus <span class="op">=</span> torch.cuda.device_count() <span class="co"># Check the number of GPUs available</span></span>
<span id="cb13-5"><a href="#cb13-5"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_gpus):</span>
<span id="cb13-6"><a href="#cb13-6"></a>    properties <span class="op">=</span> torch.cuda.get_device_properties(i)  <span class="co"># @inspect properties</span></span>
<span id="cb13-7"><a href="#cb13-7"></a></span>
<span id="cb13-8"><a href="#cb13-8"></a>y <span class="op">=</span> x.to(<span class="st">'cuda:0'</span>)  <span class="co"># Move tensor to GPU 0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>One way to check the memory usage of the GPU in PyTorch is to use the <code>torch.cuda.memory_allocated()</code> and <code>torch.cuda.memory_reserved()</code> functions. The <code>memory_allocated()</code> function returns the total memory allocated by the tensors, while the <code>memory_reserved()</code> function returns the total memory reserved by the CUDA allocator.</p>
<p>The PyTorch <code>tensor</code> are pointers to the memory allocated on the GPU, with metadata such as the shape, data type, and device. There are several commom operations that can be performed on the tensors:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode numberSource Python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a>x <span class="op">=</span> torch.tensor([[<span class="fl">1.</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]]) </span>
<span id="cb14-2"><a href="#cb14-2"></a>y <span class="op">=</span> x[<span class="dv">0</span>] <span class="co"># Get the first row of the tensor</span></span>
<span id="cb14-3"><a href="#cb14-3"></a>z <span class="op">=</span> x[:, <span class="dv">1</span>] <span class="co"># Get the second column of the tensor</span></span>
<span id="cb14-4"><a href="#cb14-4"></a>w <span class="op">=</span> x[<span class="dv">0</span>, <span class="dv">1</span>] <span class="co"># Get the element at the first row and second</span></span>
<span id="cb14-5"><a href="#cb14-5"></a></span>
<span id="cb14-6"><a href="#cb14-6"></a>y <span class="op">=</span> x.view(<span class="dv">3</span>, <span class="dv">2</span>) <span class="co"># Reshape the tensor to 3 rows and 2 columns</span></span>
<span id="cb14-7"><a href="#cb14-7"></a>z <span class="op">=</span> x.reshape(<span class="dv">3</span>, <span class="dv">2</span>) <span class="co"># Reshape the tensor to 3 rows</span></span>
<span id="cb14-8"><a href="#cb14-8"></a>w <span class="op">=</span> x.transpose(<span class="dv">0</span>, <span class="dv">1</span>) <span class="co"># Transpose the tensor </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>One of the most important operations in deep learning is the matrix multiplication, which can be performed using the <code>torch.matmul()</code> function. Also, besides that, the <code>einops</code> library provides a powerful way to manipulate tensors, allowing for more complex operations</p>
<p>Now, let‚Äôs talk about the compute account, which is the number of floating point operations (FLOPs) required to perform a certain operation. The FLOPs can be calculated as the number of floating point operations divided by the time taken to perform the operation.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The FLOPs is a measure of the computational complexity of an operation, and it is often used to compare the performance of different algorithms. The FLOP/s (FLOPs per second) is a measure of the performance of a hardware, which is the number of floating point operations that can be performed in one second. It is often used to compare the performance of different hardware, such as CPUs and GPUs.</p>
</div>
</div>
<p>Support we have a Linear layer with <code>B</code> batch size, <code>D</code> input dimension, and <code>K</code> output dimension. The number of floating point operations required to perform the forward pass of the linear layer can be calculated as:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a>FLOPs <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> B <span class="op">*</span> D <span class="op">*</span> K</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>where <code>2</code> is the number of floating point operations required to <u>perform the matrix multiplication and addition</u> (1 for multiplication and 1 for addition) of (i, j, k) triple.</p>
<p>Beside the matrix multiplication, the element-wise operations such as activation functions (e.g., ReLU, Sigmoid) also contribute to the FLOPs. For example, if we apply a ReLU activation function after the linear layer, it will add <code>B * K</code> additional floating point operations, since it applies the function to each element in the output tensor.</p>
<p>Addition of two <span class="math inline">\(m \times n\)</span> matrices requires <span class="math inline">\(mn\)</span> FLOPs, where <span class="math inline">\(m\)</span> is the number of rows and <span class="math inline">\(n\)</span> is the number of columns.</p>
<p>FLOPs is measure in terms of the number of the floating point operations required to perform a certain operation, which is a common way to measure the computational complexity of an algorithm. In theory, how to map those FLOPs to the wall clock time is not straightforward, since it depends on the hardware and the implementation of the algorithm. However, we can use the following formula to estimate the wall clock time:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a>Wall Clock Time <span class="op">=</span> FLOPs <span class="op">/</span> FLOP<span class="op">/</span>s</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>One of the criterion is the <strong>MFU(Model FLOPs Utilization)</strong>.Usually, MFU of &gt;= 0.5 is quite good (and will be higher if matmuls dominate), the MFU is defined as the ratio of the number of floating point operations to the number of floating point operations that can be performed in one second, which is the FLOP/s. The MFU can be calculated as:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a>MFU <span class="op">=</span> actual_flop_per_sec <span class="op">/</span> promised_flop_per_sec</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="eniops" class="level4">
<h4 class="anchored" data-anchor-id="eniops">Eniops</h4>
<p>It also introduce several <code>einops</code> operations:</p>
<ul>
<li><code>einsum</code> is used to perform Einstein summation notation, which is a powerful way to express complex tensor operations in a concise way.</li>
<li><code>rearrange</code> is used to change the shape of the tensor without changing the data, it is similar to <code>view</code> or <code>reshape</code> in PyTorch.</li>
<li><code>reduce</code> is used to reduce the tensor along a certain dimension, such as summing or averaging the values.</li>
<li><code>repeat</code> is used to repeat the tensor along a certain dimension, which is useful for broadcasting operations.</li>
</ul>
</section>
<section id="count-flops-for-operations" class="level4">
<h4 class="anchored" data-anchor-id="count-flops-for-operations">Count Flops for operations</h4>
<p>A floating-point operation (FLOP) is a basic operation like addition (x + y) or multiplication (x y).</p>
<ul>
<li>FLOPs: floating-point operations (measure of computation done)</li>
<li>FLOP/s: floating-point operations per second (also written as FLOPS), which is used to measure the speed of hardware.</li>
</ul>
<p>For example, the Flops for the matrix multiplication of two matrices with dimensions <code>m x n</code> and <code>n x p</code> is <code>2 * m * n * p</code>, where the <code>2</code> accounts for the multiplication and addition operations.</p>
<p>In the Linear module, the number of FLOPs can be calculated as follows:</p>
<p>Number of data points(B) x Number of parameters (D K)</p>
<p>One of the matrix is Model FLOPs utilization (MFU), which is the ratio of the number of floating point operations to the number of floating point operations that can be performed in one second, which is the FLOP/s. The MFU can be calculated as:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a>MFU <span class="op">=</span> actual_flop_per_sec <span class="op">/</span> promised_flop_per_sec</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="models" class="level3">
<h3 class="anchored" data-anchor-id="models">Models</h3>
<section id="model-parameters-initialization" class="level4">
<h4 class="anchored" data-anchor-id="model-parameters-initialization">Model Parameters Initialization</h4>
<p>The model parameters are usually initialized using a random distribution, such as the normal distribution or the uniform distribution. Such as:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a>w <span class="op">=</span> nn.Parameter(torch.randn(input_dim, out_dim))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>However, each element of <code>output</code> scales as <code>sqrt(input_dim)</code>, so we need to scale the initialization by <code>1/sqrt(input_dim)</code> to ensure that the variance of the output is not too large or too small. This is known as the <strong>Xavier initialization</strong> or <strong>Glorot initialization</strong>. The Xavier initialization can be implemented as follows:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a>w <span class="op">=</span> nn.Parameter(torch.randn(input_dim, out_dim) <span class="op">*</span> (<span class="dv">1</span> <span class="op">/</span> math.sqrt(input_dim)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To be more safe, we can truncate the normal distribution to avoid the outliers, which can be done by using the <code>torch.nn.init.trunc_normal_</code> function. The truncation can be done by specifying the <code>mean</code>, <code>std</code>, and <code>a</code> and <code>b</code> parameters, which are the lower and upper bounds of the truncation.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a>w <span class="op">=</span> nn.Parameter(torch.nn.init.trunc_normal_(torch.empty(input_dim, out_dim), mean<span class="op">=</span><span class="dv">0</span>, std<span class="op">=</span><span class="dv">1</span>, a<span class="op">=-</span><span class="dv">2</span>, b<span class="op">=</span><span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="random-seed" class="level4">
<h4 class="anchored" data-anchor-id="random-seed">Random Seed</h4>
<p>To ensure the reproducibility of the results, we need to set the random seed for the random number generator. In PyTorch, we can set the random seed using the <code>torch.manual_seed()</code> function, which will set the seed for all the random number generators in PyTorch.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a>torch.manual_seed(<span class="dv">42</span>)  <span class="co"># Set the random seed to 42</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="data-loading" class="level4">
<h4 class="anchored" data-anchor-id="data-loading">Data Loading</h4>
<p>In language modeling, data is a sequence of integer (tokens) indices, It is convenient to serialize them as numpy arrays, and load it back.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a>orig_data <span class="op">=</span> np.array([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>], dtype<span class="op">=</span>np.int32)</span>
<span id="cb23-2"><a href="#cb23-2"></a>orig_data.tofile(<span class="st">"data.npy"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If we don‚Äôt want to load the entire data into memory, we can use the <code>np.memmap</code> function to create a memory-mapped array, which allows us to access the data on disk as if it were in memory. This is useful for large datasets that cannot fit into memory.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a>data <span class="op">=</span> np.memmap(<span class="st">"data.npy"</span>, dtype<span class="op">=</span>np.int32, mode<span class="op">=</span><span class="st">"r"</span>)</span>
<span id="cb24-2"><a href="#cb24-2"></a><span class="bu">print</span>(data[<span class="dv">0</span>:<span class="dv">10</span>])  <span class="co"># Access the first 10 elements of the data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can load data using</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a><span class="kw">def</span> get_batch(</span>
<span id="cb25-2"><a href="#cb25-2"></a>    data: np.array, </span>
<span id="cb25-3"><a href="#cb25-3"></a>    batch_size: <span class="bu">int</span>, </span>
<span id="cb25-4"><a href="#cb25-4"></a>    sequence_length: <span class="bu">int</span>,</span>
<span id="cb25-5"><a href="#cb25-5"></a>    device: <span class="bu">str</span> <span class="op">=</span> <span class="st">"cpu"</span></span>
<span id="cb25-6"><a href="#cb25-6"></a>) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb25-7"><a href="#cb25-7"></a>    start_indices <span class="op">=</span> torch.randint(<span class="bu">len</span>(data) <span class="op">-</span> sequence_length, (batch_size, )) <span class="co"># Randomly select start indices for each batch</span></span>
<span id="cb25-8"><a href="#cb25-8"></a>    batch <span class="op">=</span> torch.stack([torch.tensor(data[i:i <span class="op">+</span> sequence_length]) <span class="cf">for</span> i <span class="kw">in</span> start_indices])  <span class="co"># Create a batch of sequences</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>By default, CPU tensors are in paged memory, we can explicitly pin the memory to avoid the page faults, which can be done by using the <code>pin_memory()</code> method on the tensor. This will ensure that the tensor is allocated in a contiguous block of memory, which can improve the performance of the data loading process.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb26-2"><a href="#cb26-2"></a>batch <span class="op">=</span> batch.pin_memory()  <span class="co"># Pin the memory to avoid page faults</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-pinned-memory" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pinned-memory-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./cs336.assets/lec02-pinned-memory.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pinned-memory-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Illustrate the difference between pinned memory and paged memory. The GPU cannot access data directly from pageable host memory, so when a data transfer from pageable host memory to device memory is invoked, the CUDA driver must first allocate a temporary page-locked, or ‚Äúpinned‚Äù, host array, copy the host data to the pinned array, and then transfer the data from the pinned array to device memory (Image Source: <a href="https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/">NVIDA</a>)
</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Pinned Memory vs. Paged Memory">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Pinned Memory vs.&nbsp;Paged Memory
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Paged Memory</strong>: Default system memory that <u>can be swapped out to disk by the OS</u>. Slower transfer to GPU, and does not support asynchronous transfer.</li>
<li><strong>Pinned Memory</strong>: Also called page-locked or fixed memory. It is <u>locked in RAM and cannot be swapped out</u>. Enables faster transfer to GPU and supports asynchronous transfer.</li>
</ul>
</div>
</div>
<p>This allows use to copy <code>x</code> from CPU to GPU asynchronously, which can improve the performance of the data loading process. We can use the <code>to()</code> method to move the tensor to the GPU, which will copy the tensor to the GPU memory.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb27-2"><a href="#cb27-2"></a>    batch <span class="op">=</span> batch.to(<span class="st">"cuda"</span>, non_blocking<span class="op">=</span><span class="va">True</span>)  <span class="co"># Move the batch to GPU</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This allows us to do two things in parallel (not done here):</p>
<ul>
<li>Fetch the next batch of data into CPU</li>
<li>Process x on the GPU.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This is why when we load the data using the <code>DataLoader</code> in PyTorch, we can set the <code>pin_memory=True</code> to enable the pinned memory, which will automatically pin the memory for the tensors in the data loader. This can improve the performance of the data loading process, especially when using GPUs.</p>
</div>
</div>
</section>
<section id="optimizer" class="level4">
<h4 class="anchored" data-anchor-id="optimizer">Optimizer</h4>
<p>Introduce several common optimizers in PyTorch:</p>
<ul>
<li><strong>SGD</strong>: Stochastic Gradient Descent, the most basic optimizer, which updates the parameters using the gradient of the loss function with a learning rate.</li>
<li><strong>Momentum</strong>: SGD + exponential averaging of gradients.</li>
<li>Adaptive optimizers:
<ul>
<li><strong>Adam</strong>: Adaptive Moment Estimation, which uses the first and second moments of the gradients to adaptively adjust the learning rate for each parameter.</li>
<li><strong>Adagrad</strong>: Adaptive Gradient, which adapts the learning rate based on the historical gradients.</li>
<li><strong>RMSprop</strong>: Root Mean Square Propagation, which adapts the learning rate based on the historical squared gradients.</li>
</ul></li>
</ul>
<p>Implement of <code>SGD</code> optimizer in PyTorch is as follows:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a><span class="kw">class</span> SGD(torch.optim.Optimizer):</span>
<span id="cb28-2"><a href="#cb28-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, params: Iterable[nn.Parameter], lr: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.01</span>):</span>
<span id="cb28-3"><a href="#cb28-3"></a>        <span class="bu">super</span>(SGD, <span class="va">self</span>).<span class="fu">__init__</span>(params, <span class="bu">dict</span>(lr<span class="op">=</span>lr))</span>
<span id="cb28-4"><a href="#cb28-4"></a>    <span class="kw">def</span> step(<span class="va">self</span>):</span>
<span id="cb28-5"><a href="#cb28-5"></a>        <span class="cf">for</span> group <span class="kw">in</span> <span class="va">self</span>.param_groups:</span>
<span id="cb28-6"><a href="#cb28-6"></a>            lr <span class="op">=</span> group[<span class="st">"lr"</span>]</span>
<span id="cb28-7"><a href="#cb28-7"></a>            <span class="cf">for</span> p <span class="kw">in</span> group[<span class="st">"params"</span>]:</span>
<span id="cb28-8"><a href="#cb28-8"></a>                grad <span class="op">=</span> p.grad.data</span>
<span id="cb28-9"><a href="#cb28-9"></a>                p.data <span class="op">-=</span> lr <span class="op">*</span> grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Also the <code>AdaGrad</code> optimizer can be implemented as follows:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a><span class="kw">class</span> AdaGrad(torch.optim.Optimizer):</span>
<span id="cb29-2"><a href="#cb29-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, params: Iterable[nn.Parameter], lr: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.01</span>):</span>
<span id="cb29-3"><a href="#cb29-3"></a>        <span class="bu">super</span>(AdaGrad, <span class="va">self</span>).<span class="fu">__init__</span>(params, <span class="bu">dict</span>(lr<span class="op">=</span>lr))</span>
<span id="cb29-4"><a href="#cb29-4"></a>    <span class="kw">def</span> step(<span class="va">self</span>):</span>
<span id="cb29-5"><a href="#cb29-5"></a>        <span class="cf">for</span> group <span class="kw">in</span> <span class="va">self</span>.param_groups:</span>
<span id="cb29-6"><a href="#cb29-6"></a>            lr <span class="op">=</span> group[<span class="st">"lr"</span>]</span>
<span id="cb29-7"><a href="#cb29-7"></a>            <span class="cf">for</span> p <span class="kw">in</span> group[<span class="st">"params"</span>]:</span>
<span id="cb29-8"><a href="#cb29-8"></a>                <span class="co"># Optimizer state</span></span>
<span id="cb29-9"><a href="#cb29-9"></a>                state <span class="op">=</span> <span class="va">self</span>.state[p]</span>
<span id="cb29-10"><a href="#cb29-10"></a>                grad <span class="op">=</span> p.grad.data</span>
<span id="cb29-11"><a href="#cb29-11"></a>                <span class="co"># Get squared gradients g2 = sum_{i&lt;t} g_i^2</span></span>
<span id="cb29-12"><a href="#cb29-12"></a>                g2 <span class="op">=</span> state.get(<span class="st">"g2"</span>, torch.zeros_like(grad))</span>
<span id="cb29-13"><a href="#cb29-13"></a>                <span class="co"># Update optimizer state</span></span>
<span id="cb29-14"><a href="#cb29-14"></a>                g2 <span class="op">+=</span> torch.square(grad)</span>
<span id="cb29-15"><a href="#cb29-15"></a>                state[<span class="st">"g2"</span>] <span class="op">=</span> g2</span>
<span id="cb29-16"><a href="#cb29-16"></a>                <span class="co"># Update parameters</span></span>
<span id="cb29-17"><a href="#cb29-17"></a>                p.data <span class="op">-=</span> lr <span class="op">*</span> grad <span class="op">/</span> torch.sqrt(g2 <span class="op">+</span> <span class="fl">1e-5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The usage of the optimizer is as follows:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a>model <span class="op">=</span> MyModel()</span>
<span id="cb30-2"><a href="#cb30-2"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb30-3"><a href="#cb30-3"></a></span>
<span id="cb30-4"><a href="#cb30-4"></a>x_in <span class="op">=</span> torch.randn(<span class="dv">32</span>, <span class="dv">100</span>)  <span class="co"># Input tensor</span></span>
<span id="cb30-5"><a href="#cb30-5"></a>y_out <span class="op">=</span> model(x_in)  <span class="co"># Forward pass</span></span>
<span id="cb30-6"><a href="#cb30-6"></a>target <span class="op">=</span> torch.randn(<span class="dv">32</span>, <span class="dv">10</span>)  <span class="co"># Target tensor</span></span>
<span id="cb30-7"><a href="#cb30-7"></a>loss <span class="op">=</span> loss_fn(y_out, target)  <span class="co"># Compute loss</span></span>
<span id="cb30-8"><a href="#cb30-8"></a></span>
<span id="cb30-9"><a href="#cb30-9"></a>loss.backward()  <span class="co"># Backward pass</span></span>
<span id="cb30-10"><a href="#cb30-10"></a>optimizer.step()  <span class="co"># Update parameters</span></span>
<span id="cb30-11"><a href="#cb30-11"></a>optimizer.zero_grad(set_to_none<span class="op">=</span><span class="va">True</span>) <span class="co"># Zero gradients for the next iteration # Set to None is more memory efficient</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="training-loop" class="level4">
<h4 class="anchored" data-anchor-id="training-loop">Training Loop</h4>
</section>
<section id="checkpointing" class="level4">
<h4 class="anchored" data-anchor-id="checkpointing">Checkpointing</h4>
</section>
<section id="mixed-precision-training" class="level4">
<h4 class="anchored" data-anchor-id="mixed-precision-training">Mixed Precision Training</h4>
<p>Choice of data type (float32, bfloat16, fp8) have tradeoffs.</p>
<p>Higher precision: more accurate/stable, more memory, more compute</p>
<p>Lower precision: less accurate/stable, less memory, less compute</p>
<p>We can use <a href="https://arxiv.org/abs/1710.03740">mixed precision training</a> to balance the tradeoffs, which is a common practice in deep learning to save memory and speed up training without sacrificing too much performance. The idea is to use <code>float16</code> &nbsp;<code>bfloat16</code> for the model parameters and gradients, and <code>float32</code> for the optimizer state. This can be done using the <code>torch.cuda.amp</code> module in PyTorch, which provides automatic mixed precision training.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a>scaler <span class="op">=</span> torch.cuda.amp.GradScaler()  <span class="co"># Create a GradScaler for mixed precision training</span></span>
<span id="cb31-2"><a href="#cb31-2"></a><span class="cf">for</span> data, target <span class="kw">in</span> dataloader:</span>
<span id="cb31-3"><a href="#cb31-3"></a>    optimizer.zero_grad(set_to_none<span class="op">=</span><span class="va">True</span>)  <span class="co"># Zero gradients for the next iteration</span></span>
<span id="cb31-4"><a href="#cb31-4"></a>    <span class="cf">with</span> torch.cuda.amp.autocast():  <span class="co"># Enable autocasting for mixed precision training</span></span>
<span id="cb31-5"><a href="#cb31-5"></a>        output <span class="op">=</span> model(data)  <span class="co"># Forward pass</span></span>
<span id="cb31-6"><a href="#cb31-6"></a>        loss <span class="op">=</span> loss_fn(output, target)  <span class="co"># Compute loss</span></span>
<span id="cb31-7"><a href="#cb31-7"></a>    scaler.scale(loss).backward()  <span class="co"># Backward pass with scaled loss</span></span>
<span id="cb31-8"><a href="#cb31-8"></a>    scaler.step(optimizer)  <span class="co"># Update parameters with scaled gradients</span></span>
<span id="cb31-9"><a href="#cb31-9"></a>    scaler.update()  <span class="co"># Update the scaler for the next iteration</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="summary-of-lecture-02" class="level3">
<h3 class="anchored" data-anchor-id="summary-of-lecture-02">Summary of Lecture 02</h3>
</section>
</section>
<section id="lecture-03-architectures-hyperparameters" class="level2">
<h2 class="anchored" data-anchor-id="lecture-03-architectures-hyperparameters">Lecture 03: Architectures &amp; Hyperparameters</h2>
</section>
<section id="lecture-04-mixture-of-experts" class="level2">
<h2 class="anchored" data-anchor-id="lecture-04-mixture-of-experts">Lecture 04: Mixture of Experts</h2>
</section>
<section id="lecture-05-06-gpu-kernels-triton" class="level2">
<h2 class="anchored" data-anchor-id="lecture-05-06-gpu-kernels-triton">Lecture 05 &amp; 06: GPU, Kernels, Triton</h2>
</section>
<section id="lecture-07-08-parallelism" class="level2">
<h2 class="anchored" data-anchor-id="lecture-07-08-parallelism">Lecture 07 &amp; 08: Parallelism</h2>
</section>
<section id="lecture-09-11-scaling-laws" class="level2">
<h2 class="anchored" data-anchor-id="lecture-09-11-scaling-laws">Lecture 09 &amp; 11: Scaling Laws</h2>
</section>
<section id="lecture-10-inference" class="level2">
<h2 class="anchored" data-anchor-id="lecture-10-inference">Lecture 10: Inference</h2>
</section>
<section id="lecture-12-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="lecture-12-evaluation">Lecture 12: Evaluation</h2>
</section>
<section id="lecture-13-14-data" class="level2">
<h2 class="anchored" data-anchor-id="lecture-13-14-data">Lecture 13 &amp; 14: Data</h2>
</section>
<section id="lecture-15-16-17-alignment-sft-rlhf" class="level2">
<h2 class="anchored" data-anchor-id="lecture-15-16-17-alignment-sft-rlhf">Lecture 15, 16 &amp; 17: Alignment: SFT/ RLHF</h2>
</section>
</section>
<section id="assignments" class="level1">
<h1>Assignments</h1>
<section id="assignment-01-basics" class="level2">
<h2 class="anchored" data-anchor-id="assignment-01-basics">Assignment 01: Basics</h2>
<section id="preparation" class="level3">
<h3 class="anchored" data-anchor-id="preparation">Preparation</h3>
<section id="clone-assignment-repository" class="level4">
<h4 class="anchored" data-anchor-id="clone-assignment-repository">Clone Assignment Repository</h4>
<p>First, we need clone the assignment repository from GitHub:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone https://github.com/stanford-cs336/assignment1-basics/tree/main</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> assignment1-basics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="download-dataset" class="level4">
<h4 class="anchored" data-anchor-id="download-dataset">Download Dataset</h4>
<p>Then, we need download the dataset, the dataset used are <a href="https://huggingface.co/datasets/roneneldan/TinyStories">TinyStories</a> and <a href="https://github.com/jcpeterson/openwebtext">OpenWebText</a></p>
<div class="sourceCode" id="cb33"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> <span class="at">-p</span> data</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> data</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-train.txt</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-valid.txt</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_train.txt.gz</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="fu">gunzip</span> owt_train.txt.gz</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_valid.txt.gz</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="fu">gunzip</span> owt_valid.txt.gz</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ..</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>After downloading the dataset, we can check the size of the dataset:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">du</span> <span class="at">-sh</span> ./data             </span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 13G    ./data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>There are 13GB of data in total, which is a small dataset for training a language model.</p>
</section>
<section id="install-dependencies" class="level4">
<h4 class="anchored" data-anchor-id="install-dependencies">Install Dependencies</h4>
<p>To run code, and install the dependencies, we can just run the following command:</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="ex">uv</span> run python</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>It will automatically create a virtual environment and install the dependencies.</p>
</section>
</section>
<section id="byte-pair-encoding-bpe-tokenizer" class="level3">
<h3 class="anchored" data-anchor-id="byte-pair-encoding-bpe-tokenizer">Byte-Pair Encoding (BPE) Tokenizer</h3>
<section id="the-unicode-standard" class="level4">
<h4 class="anchored" data-anchor-id="the-unicode-standard">The Unicode Standard</h4>
<div class="sourceCode" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1"></a><span class="bu">ord</span>() <span class="co"># convert a single Unicode character into its integer representation</span></span>
<span id="cb36-2"><a href="#cb36-2"></a><span class="bu">chr</span>() <span class="co"># convert a single integer representation into its Unicode character</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The Unicode character <code>chr(0)</code> return <code>'\x00'</code>, which is the null character. While use <code>repr(chr(0))</code> will return <code>"'\\x00'"</code>, which is the string representation of the null character. When use <code>print</code> function, it will not print anything, since the null character is not printable. So, when add the <code>chr(0)</code> to the string, it will not change the string, but it will add a null character to string.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1"></a><span class="co">"this is a test"</span> <span class="op">+</span> <span class="bu">chr</span>(<span class="dv">0</span>) <span class="op">+</span> <span class="st">"string"</span> <span class="co"># 'this is a test\x00string'</span></span>
<span id="cb37-2"><a href="#cb37-2"></a><span class="bu">print</span>(<span class="st">"this is a test"</span> <span class="op">+</span> <span class="bu">chr</span>(<span class="dv">0</span>) <span class="op">+</span> <span class="st">"string"</span>) <span class="co"># # this is a teststring</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="unicode-encoding" class="level4">
<h4 class="anchored" data-anchor-id="unicode-encoding">Unicode Encoding</h4>
<p>Unicode Encoding is the process of converting a Unicode character into a sequence of bytes. The most common encoding is UTF-8, which uses 1 to 4 bytes to represent a Unicode character.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Unicode Standard VS. Unicode Encoding">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Unicode Standard VS. Unicode Encoding
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Unicode Standard</strong> is a character encoding standard that <u>defines a unique number for every character</u>, no matter the platform, program, or language. <strong>Unicode Encoding</strong> is the <u>actual implementation of the Unicode Standard</u> in a specific encoding format, such as UTF-8 or UTF-16. It will convert the Unicode character into a sequence of bytes.</p>
</div>
</div>
<p>To encode the Unicode string into UTF-8, we can use the <code>encode()</code> method in Python to convert the string into a byte sequence, and then use the <code>decode()</code> method to convert the byte sequence back into a string. The <code>encode()</code> method takes an optional argument that specifies the encoding format, which is UTF-8 by default.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1"></a>original_string <span class="op">=</span> <span class="st">"Hello World! üåç ‰Ω†Â•Ω, ‰∏ñÁïå!"</span></span>
<span id="cb38-2"><a href="#cb38-2"></a>utf8_encode <span class="op">=</span> original_string.encode(<span class="st">"utf-8"</span>)</span>
<span id="cb38-3"><a href="#cb38-3"></a>utf8_bytes <span class="op">=</span> <span class="bu">list</span>(utf8_encode) <span class="co"># Get the byte values of the encoded string</span></span>
<span id="cb38-4"><a href="#cb38-4"></a>original_string <span class="op">=</span> utf8_encode.decode(<span class="st">"utf-8"</span>)</span>
<span id="cb38-5"><a href="#cb38-5"></a><span class="bu">len</span>(original_string) <span class="co"># 22</span></span>
<span id="cb38-6"><a href="#cb38-6"></a><span class="bu">len</span>(utf8_bytes) <span class="co"># 33</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>UTF-8 is variable-length and uses 1 byte for ASCII (common in English), making it more compact for most real-world text. UTF-16 uses 2 or 4 bytes per character, and UTF-32 always uses 4 bytes, even for ASCII.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1"></a>s <span class="op">=</span> <span class="st">"hello"</span></span>
<span id="cb39-2"><a href="#cb39-2"></a><span class="bu">print</span>(<span class="bu">len</span>(s.encode(<span class="st">"utf-8"</span>)))   <span class="co"># 5 bytes</span></span>
<span id="cb39-3"><a href="#cb39-3"></a><span class="bu">print</span>(<span class="bu">len</span>(s.encode(<span class="st">"utf-16"</span>)))  <span class="co"># 12 bytes (includes BOM)</span></span>
<span id="cb39-4"><a href="#cb39-4"></a><span class="bu">print</span>(<span class="bu">len</span>(s.encode(<span class="st">"utf-32"</span>)))  <span class="co"># 20 bytes (includes BOM)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>UTF-8 produces a byte range of 0‚Äì255, making the vocabulary size small and fixed (ideal for BPE training).
‚Ä¢   UTF-16/32 would increase the vocabulary size dramatically (‚â•65,536 for UTF-16 and ~4 billion for UTF-32), requiring larger models and memory.</code></pre>
<p>bytes() creates an immutable sequence of bytes ‚Äî that is, a sequence of integers in the range 0‚Äì255.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1"></a>s <span class="op">=</span> <span class="st">"hello üåç"</span></span>
<span id="cb41-2"><a href="#cb41-2"></a>b <span class="op">=</span> <span class="bu">bytes</span>(s, <span class="st">"utf-8"</span>)</span>
<span id="cb41-3"><a href="#cb41-3"></a><span class="bu">print</span>(b)  <span class="co"># b'hello \xf0\x9f\x8c\x8d'</span></span>
<span id="cb41-4"><a href="#cb41-4"></a>b <span class="op">=</span> s.encode(<span class="st">"utf-8"</span>)</span>
<span id="cb41-5"><a href="#cb41-5"></a></span>
<span id="cb41-6"><a href="#cb41-6"></a>b <span class="op">=</span> <span class="bu">bytes</span>([<span class="dv">104</span>, <span class="dv">101</span>, <span class="dv">108</span>, <span class="dv">108</span>, <span class="dv">111</span>])  <span class="co"># equivalent to 'hello'</span></span>
<span id="cb41-7"><a href="#cb41-7"></a><span class="bu">print</span>(b)  <span class="co"># b'hello'</span></span>
<span id="cb41-8"><a href="#cb41-8"></a></span>
<span id="cb41-9"><a href="#cb41-9"></a>b <span class="op">=</span> <span class="bu">bytes</span>(<span class="dv">5</span>)</span>
<span id="cb41-10"><a href="#cb41-10"></a><span class="bu">print</span>(b)  <span class="co"># b'\x00\x00\x00\x00\x00'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb42"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1"></a>decode_utf8_bytes_to_str_wrong(<span class="st">"üåç"</span>.encode(<span class="st">"utf-8"</span>))</span>
<span id="cb42-2"><a href="#cb42-2"></a><span class="co"># Raises: UnicodeDecodeError</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The function is incorrect because it decodes each byte individually, but multi-byte UTF-8 characters (like ‚Äòüåç‚Äô) must be decoded as a whole sequence, not byte-by-byte.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1"></a><span class="bu">bytes</span>([<span class="bn">0xc0</span>, <span class="bn">0x20</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="bpe-tokenizer-training" class="level4">
<h4 class="anchored" data-anchor-id="bpe-tokenizer-training">BPE Tokenizer Training</h4>
<p>Three steps:</p>
<ol type="1">
<li>Vocabulary Initialization</li>
<li>Pre-Tokenization</li>
<li>Compute BPE merges</li>
<li>Handle Special Tokens</li>
</ol>
</section>
</section>
</section>
<section id="assignment-02-system" class="level2">
<h2 class="anchored" data-anchor-id="assignment-02-system">Assignment 02: System</h2>
<p>In this assignment, we will profile and benchmark the model we built in the assignment 01, and optimize the attention mechanism using Triton by implementing the FlashAttention2<span class="citation" data-cites="FlashAttention2FasterAttention2023dao">(<a href="#ref-FlashAttention2FasterAttention2023dao" role="doc-biblioref">Dao 2023</a>)</span>.</p>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-FlashAttention2FasterAttention2023dao" class="csl-entry" role="listitem">
Dao, Tri. 2023. <span>‚Äú<span>FlashAttention-2</span>: <span>Faster Attention</span> with <span>Better Parallelism</span> and <span>Work Partitioning</span>.‚Äù</span> July 17, 2023. <a href="https://doi.org/10.48550/arXiv.2307.08691">https://doi.org/10.48550/arXiv.2307.08691</a>.
</div>
<div id="ref-MixedPrecisionTraining2018micikevicius" class="csl-entry" role="listitem">
Micikevicius, Paulius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, et al. 2018. <span>‚ÄúMixed <span>Precision Training</span>.‚Äù</span> February 15, 2018. <a href="https://doi.org/10.48550/arXiv.1710.03740">https://doi.org/10.48550/arXiv.1710.03740</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../posts/Gen-AI/kaist-diffusion-models.html" class="pagination-link" aria-label="KAIST CS492(D): *Diffusion Models and Their Applications*">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">KAIST CS492(D): <em>Diffusion Models and Their Applications</em></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../posts/Gen-AI/ucb-deep-unsupervised.html" class="pagination-link" aria-label="CS294-158: *Deep Unsupervised Learning*">
        <span class="nav-page-text">CS294-158: <em>Deep Unsupervised Learning</em></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>¬© CC-By Yuyang, 2025</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This page is built with ‚ù§Ô∏è and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>